# SmartDocs: An√°lise Arquitetural End-to-End

Esta documenta√ß√£o consolida a vis√£o arquitetural do projeto SmartDocs, listando seus pontos fortes tecnol√≥gicos, potenciais gargalos e estrat√©gias pr√°ticas de melhoria e escalabilidade.

## üèóÔ∏è Vis√£o Arquitetural (End-to-End)

### 1. Frontend (Interface e Intera√ß√£o)
* **Stack**: Next.js 16, React 19, Tailwind CSS v4.
* **UI/UX**: Integra√ß√£o com Shadcn UI, Radix UI e Lucide React, promovendo uma base de componentes flex√≠vel, limpa e altamente customiz√°vel.
* **Visualiza√ß√£o de Dados**: Uso de `@tanstack/react-table` para renderiza√ß√£o de tabelas e dataframes din√¢micos gerados pelo agente. `react-markdown` para formata√ß√£o das respostas da IA.

### 2. Backend (Core e APIs)
* **Stack**: FastAPI com arquitetura fortemente ass√≠ncrona.
* **Banco de Dados**: PostgreSQL com `asyncpg` e `SQLAlchemy 2.0`.
* **Seguran√ßa**: Autentica√ß√£o nativa baseada em JWT com hashing seguro usando `pwdlib[argon2]`.
* **Integra√ß√£o de Arquivos e Nuvem**: Azure AI Document Intelligence para extra√ß√£o de conte√∫do estruturado, e Azure Blob Storage para o armazenamento f√≠sico e escal√°vel dos anexos.

### 3. Intelig√™ncia Artificial (Agentic AI)
* **Orquestra√ß√£o**: Baseado em LangChain e LangGraph, estruturando fluxos de chat multicamadas que misturam gera√ß√£o de texto com chamadas de banco de dados (`database_query tool`).
* **Busca Sem√¢ntica (RAG)**: Armazenamento vetorial via extens√£o `pgvector` nativa no PostgreSQL, mantendo embeddings perfeitamente integrados ao banco relacional.

---

## ‚ö†Ô∏è Potenciais Gargalos e Riscos

1. **Processamento S√≠ncrono de Extratos Longos (Azure AI)**
   * **Risco**: Hoje a chamada para o Azure Document Intelligence ocorre no fluxo da requisi√ß√£o HTTP local (FastAPI). Documentos com dezenas de p√°ginas causar√£o *timeouts* na API, sobrecarga nos workers Uvicorn e paralisa√ß√£o infinita na UI para o usu√°rio final.

2. **Seguran√ßa e Escopo do Agente SQL (Database Query Tool)**
   * **Risco**: Se o agente possuir acesso irrestrito ao *schema* ou usar uma *connection string* com permiss√µes de grava√ß√£o, eventuais alucina√ß√µes (ex: confus√£o devido a colunas removidas, como `document_type`) podem vazar dados indesejados ou at√© rodar queries pesadas que afetem a performance do banco.

3. **Performance da Busca no RAG: Vetorial vs. Exata**
   * **Risco**: `pgvector` e buscas em embeddings (busca sem√¢ntica) perdem muita precis√£o quando o usu√°rio demanda buscas exatas, como ids de documentos ("contrato 12345") ou valores nominais absolutos.

4. **Incha√ßo de Contexto (*Context Window* do LLM)**
   * **Risco**: A interface agora renderiza *DataTables* complexas geradas como parte do envio das respostas. Se esses *datasets* brutos forem re-enviados nas mensagens consecutivas do hist√≥rico (mem√≥ria do LangGraph), o custo financeiro da OpenAI subir√° drasticamente e novos limites de *tokens* ser√£o estourados muito rapidamente.

---

## üí° Estrat√©gias de Melhoria e Evolu√ß√£o

1. **Processamento Ass√≠ncrono via Workers/Filas (Background Tasks)**
   * **Solu√ß√£o**: Isolar a extra√ß√£o via Azure. O upload no backend gera apenas uma *Task* e guarda o PDF no Azure Blob Storage com status "Processando". Filas (via Celery, Redis ou tabelas pr√≥prias no PostgreSQL) acionam o script em segundo plano sem prender o FastAPI, e notificam a UI ao concluir (via WebSockets ou *Polling*).

2. **Inje√ß√£o de Contexto Limitada para o Agente ("Schema Trimming")**
   * **Solu√ß√£o**: Restringir drasticamente o schema de tabelas vis√≠vel no prompt de sistema das *Database Tools*. Ocultar colunas irrelevantes √† busca (como `updated_at`, `password_hash`, IDs sist√™micos). Prover apenas as chaves necess√°rias relacionais.

3. **Busca H√≠brida (Hybrid Search Engine)**
   * **Solu√ß√£o**: Mesclar as buscas vetoriais (`pgvector`) com algoritmos L√©xicos baseados em palavra-chave exata (Full-Text Search do PostgreSQL ou BM25 do Elastic/Meili). O AI cruzar√° os dois √≠ndices garantindo os melhores "conceitos" e os "ids/nomes" simultaneamente.

4. **Resumo Autom√°tico de Mem√≥ria (Pagina√ß√£o de Hist√≥rico AI)**
   * **Solu√ß√£o**: Enviar tabelas preenchidas pro LLM apenas na pr√≥xima mensgem. Para intera√ß√µes antigas, varrer a vari√°vel do Hist√≥rico substituindo os JSON longos por respostas encurtadas na mem√≥ria do chat. Ex: `[O sistema retornou uma tabela com N linhas contendo o relat√≥rio solicitado]`.

5. **Observabilidade e Monitoramento de IA (LLM Tracing)**
   * **Solu√ß√£o**: Adicionar integra√ß√µes aos *callbacks* do LangChain (ex: LangSmith ou Phoenix). Auxilia enormemente na corre√ß√£o de bugs dos Prompts exibindo em uma UI o que o LLM "pensou", ferramentas executadas, os dados pesquisados, e falhas de racioc√≠nio.
